# スタックとヒープ

## malloc

>「前回、文字列は文字の配列で、配列は後から追加出来ないって言ってましたよね？」 

言ったね。それで？

>「困りますよね？」

うーん・・・まあ、困るかな。

>「例えば、テキストエディタを作るとするじゃないですか。ファイルから文字列を読み込みますよね。
> でも、大きいファイルも小さいファイルもあるわけだから、その文字列を読み込む配列を
> あらかじめ作っておくことはできませんよね？」

できないね。

うん。今までの話をちゃんと理解していれば、当然出てくる疑問だ。

本題に入る前に、言っておこう。テキストエディタは読み込んだファイルを
大きな1つの文字列に保存するわけではない。
そんなことしたら、途中の文字を削除したときに、
末尾の文字まで延々ひとつずつずらすことに
なりかねない。
配列はメモリ上に連続して入ってなければならないからね。
いろいろなやり方があると思うけど、
典型的には、各行ごとの文字列を作って、それをリストにしているんだと思う。

ここでいうリストというのは、日常的に使う用語としてのリストではなく、
データ構造の名前としてのリストだ。
リストにもいくつかの種類がある。
例えば、JavaのAPIにはjava.util.ArrayListとjava.util.LinkedListがある。
どちらもリストという名前だけど、種類が違うので用途によって使い分けるべきだ。
何にも考えずにArrayListを使ってる人も多そうだけど、
実は単に「リスト」と呼んだときにデータ構造を学んだプログラマの頭に思い浮かぶものに
近いのはLinkedListだったりする。

> 「・・・そもそもLinkedListの存在を知りませんでした」

まあ、そういう人は一定数いると思う。

今回はデータ構造の説明はしないけど、アルゴリズムとデータ構造は
コンピューターサイエンスの基礎の基礎だ。
プログラムはプログラミング言語を習得すれば書けるようになると
誤解している人が多いし、プログラミング言語を習得する中で
学んでいくことも多いと思うけど、
ある程度、プログラムを書くことに慣れたら、
ぜひ、アルゴリズムとデータ構造の本にチャレンジしてみて欲しい。
そして、そういう基礎を学ぶときにC言語の知識はそのとききっと役に立つはずだ。

さて、それはともかくだ。
プログラムを作っていたら、実行時にしかサイズが分からない配列を作りたいことはある。
つまり、動的にサイズが決まる配列だ。
もちろん、C言語でも動的にサイズが決まる配列を作ることが出来る。

・・・というか、必要なだけのメモリを取得することが出来る。
そのメモリ領域を配列だと考えてアクセスするのはプログラマの自由だ。
メモリを取得するには、mallocを使う。

> 「まろっく？」

読み方までは知らないな。Memory を ALLCate するんだから、「えむあろっく」かも？

さて、使い方はこんな感じだ。

```c
int *ary = malloc(sizeof(int) * 1000)
```

こうすると、intのサイズが1000個分のメモリ領域が確保されて、
そのアドレスが返ってくる。
以前説明したとおり、配列の記法`ary[i]`は`&(ary + i)`とまったく同じモノなので、
aryを配列だと思ってプログラムを書いてまったく問題ない。

ただし、3つ注意点がある。

まず、mallocは空いたメモリを見つけてそこを確保してくれるが、
そのメモリ上に何が書いてあるかは気にしない。
必要があれば、そこを全部0で埋めるなどの初期化が必要になる。
つまり、上の例で言えば、いきなり`ary[555]`を読むことができるけど、
何が返ってくるかは分からない。
間違っても0が書いてあることを前提としたコードを書いてはいけない。

2つ目は領域外へのアクセスだ。先頭アドレスが入ったポインタだけしかないわけだから、
サイズは別途管理すること。確保した領域外を読んだり書いたりすると不幸が起きる。
配列を関数の引数で渡したときと似た話だね。

最後に、mallocで確保した領域は、要らなくなったら明示的に解放しなければならない。
解放はfree関数にポインタを渡せば良い。
mallocしてfreeし忘れるというのは、典型的なバグだ。
そうすると何が起きるかというと、プログラムを動かしている間に使っているメモリ量が
どんどん増えていく一方になる。
いわゆる「メモリリーク」で、最終的にはシステムのメモリを食い潰してしまう。

こんなところかな。

## なぜローカル変数はFreeしなくてもよいのか

> 「つまり、プログラムを書いているときに『ここでメモリが使いたい。データを取っておきたい』と思ったら変数を宣言すればそこにデータを入れられる。でも、もう動かしている時に『書いていた時にはどれだけ必要かわからなかったけど、今はわかったからそれだけメモリが欲しい』となるなら、そのときにmalloc()するようなプログラムを書いておけということ・・・？」

それであってるよ。

>「どちらにせよ、書いてるときに決めておくしかないんですね」

まあ、それがプログラムというものだね。プログラムが動きながら自分自身を書き換えていくようなことをしない限り。まあ、そんな怪しいことは今は考えない方が良い。

>「ちなみに、『メモリをください』というのが私の書いたプログラムだとして、メモリをくれるのは誰ですか？」

オペレーションシステム(OS)だ。OSがメモリーを管理している。

>「でも、OSもプログラムですよね？OSは誰からメモリを貰うんですか？」

誰からも。OSにとってハードウェアに積まれているメモリは全部自分のものだ。誰に断ることもなく、勝手にどのアドレスでも使っていい。もちろん、現代のCPUやコンピューターにはハードウェアにメモリ管理のための仕組みがあるので、OSはメモリ管理にそれを使って楽をする。以前にインテルのCPUのプロテクトモードの話をしたよね。だけども、非常にプリミティブに言えば、OSは勝手にどこでもつかっていいし、逆に言えばどこを使っているかは自分で管理しなきゃいけない。さらに、OSの管理下で動いているプログラムにどのメモリを貸し出しているか全部コントロールしなきゃいけない。OSさんは大変なお仕事だ。

>「感謝ですね!」

もちろん、OSごとにメモリを要求する命令は違うかもしれない。しかし、C言語でmalloc()と書けば、コンパイルしたプログラムでは各OSごとのメモリ要求命令に変換される。メモリという実体はそのまま扱っているけど、メモリ要求という手続きは抽象化して、プログラムの移植性を高めているんだね。これがもっと高級な言語なら、確保したメモリのポインタとサイズというメモリの実体そのものじゃなくて、例えば「オブジェクト」のようなもっと抽象的なものが貰える。このあたりがC言語っぽいところだ。

>「なんとなくC言語っぽいレベル感がわかってきました」

そして、OSにとって、概してmalloc()は面倒な処理だ。まず、空いているメモリを探さなきゃいけない。見つけたらそこを使用済みとして管理台帳に載せなければならない。細切れの使用済み領域がたくさん出来たら新しいメモリ要求に応えられないかも知れないから、ときどき区画整理をしないといけないかも知れない。そして、それを全てのプログラム相手にやらなければならない。

なので、ここは工夫のしどころだ。例えば、OSがあらかじめ使いそうな量を確保しておいてくれるかもしれない。コンパイラが複数回のmalloc()を裏でまとめて一回で済むようなプログラムに最適化してくれるかもしれない。プログラマの方で大きめに要求して自分で小さくちぎって使うように気を遣ってるなんて、優しいプログラマもいるだろう。とにかく、巨大なメモリ要求や、少量ずつの大量のメモリ要求を処理するのは大変なので、みんなが頑張ってる。なので、malloc()したら裏でいろんなことが起きているかもしれない。でも、まあ、使う方の理想は、アドレスをただありがとうといって使うだけだ。malloc()に伴うパフォーマンスの影響を考えるのは、もっとCプログラマとして経験を積んでからでいい。ただ、malloc()はそれなりにコストが高い処理で、裏で工夫もされているから毎回ホントにメモリを探して、予約して・・・という全部のプロセスがちまちまされているとは限らないということは覚えておいて欲しい。いざ、プログラムが遅くて、malloc()に時間がかかってることがわかって困ったら思い出してね。

>「感謝する心が深まりました。そうかー、私が変数を宣言してデータを入れる度に、OSさんは裏でメモリを用意してくれてたんですね。ありがたや、ありがたや」

いや、malloc()したときだけだよ。ローカル変数を使う時には、OSはいちいちメモリをくれたりしない。

>「ふぁ！？」

だって、ローカル変数はfree()しないだろう？

>「それは・・・関数の最後に自動的にしてくれるんじゃないんですか？」

なるほど・・・そうだね。そういう仕組みにすることは可能だ。でも、さっきも言ったとおりmalloc()やfree()はそれなりにコストがかかる処理だから、たくさん使われるローカル変数では使わない。ローカル変数はメモリの中の「スタック領域」を使う。ちなみに、malloc()したらメモリが取られる領域は「ヒープ領域」だ。この2つはアドレス空間の全然違う位置にある。

おおざっぱに仕組みを説明しよう。まず、プログラムを実行する際には、あらかじめメモリの中に「スタック領域」としてある程度のメモリが確保される。そのスタック領域の先頭のアドレスをあらかじめどこかに控えておく。関数が実行されて次々にローカル変数が宣言されると、そのスタック領域の端っこから順にローカル変数に割り当てられる。すでに確保済みの領域なので、OSへのメモリ要求は発生せずに素早く変数にメモリを割り当てることが出来る。今、使用済みの位置はどのアドレスまでかをどこかに書いておけば、次のローカル変数の割り当てはそこから始めれば良い。

ここで理解しておかなければならないのは、関数の実行中に2つのアドレスを管理しておかなければならないことだ。スタック領域の先頭のアドレスと、今どこまで割り当て済みかを表すアドレスの2つだ。スタック領域の先頭のアドレスは関数の実行中には変化しない。割り当て済みを表すアドレスはずっと増えていく。ここまではいいかな？

>「はい。使っている領域の先頭と末尾のアドレスを持っておく。わかります」

使っているメモリ量は、その2つのアドレスの差だ。そして、関数が終了したとしよう。使っていたローカル変数はすべて無くなる。そのときはどうするかというと、割り当て済みを表すアドレスに先頭のアドレスをコピーする。

>「ん？」

すると、使っている領域のサイズは0になる。次にメモリを確保するのはまた末尾のアドレスからだけど、それは先頭に巻き戻っているので、さっき使っていたばっかりの領域をリサイクルして使う事になる。簡単だね。

>「簡単ですけど・・・何が嬉しいのかよくわかりません」

そうだね。そもそもなぜ「スタック」という名前なのかもわからないね。スタックもリストと同じように基本的なデータ構造の名前なんだけど、そもそもは「積み重ねる」という意味だ。

## 関数呼び出しとは何か





